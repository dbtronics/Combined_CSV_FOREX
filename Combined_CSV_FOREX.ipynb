{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbtronics/Combined_CSV_FOREX/blob/main/Combined_CSV_FOREX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4TpZVPALByV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install mplfinance\n",
        "import mplfinance as mpf\n",
        "from datetime import datetime\n",
        "import os\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpDom94tvvgx"
      },
      "outputs": [],
      "source": [
        "acct_id = '8908'\n",
        "\n",
        "start_year = 2024\n",
        "end_year = 2024\n",
        "\n",
        "start_month = 4\n",
        "end_month = 4\n",
        "\n",
        "start_day = 15\n",
        "end_day = 19\n",
        "\n",
        "period_string = \"Weekly\"\n",
        "\n",
        "start_date = datetime(start_year, start_month, start_day)\n",
        "end_date = datetime(end_year, end_month, end_day)\n",
        "\n",
        "pd_date_extraction = pd.date_range(start = start_date, end = end_date, freq = \"D\")\n",
        "date_extraction = pd_date_extraction.strftime(\"%Y%m%d\")\n",
        "# This is an estimate based on how much we can expect balance to sharply change based on user external input to withdraw or change balance\n",
        "diff_percentage = 0.25\n",
        "\n",
        "# Change output file name to one that you want\n",
        "output_filename = str(acct_id)+\"_\"+str(period_string)+\"_Performance(\"+date_extraction[0]+\"-\"+date_extraction[-1]+\").csv\"\n",
        "print(output_filename)\n",
        "\n",
        "# Put the exact name that you used to make a folder inside the google colab\n",
        "internal_foldername = str(acct_id)+\"_data\"\n",
        "print(internal_foldername)\n",
        "\n",
        "# this data is for candlestick chart pattern\n",
        "time_frequency = \"2H\" # hourly specify\n",
        "output_title = str(acct_id)+\"_\"+str(period_string)+\"_Performance(\"+date_extraction[0]+\"-\"+date_extraction[-1]+\")\"\n",
        "output_filename_candlestick = str(acct_id)+\"_\"+str(period_string)+\"_Performance(\"+date_extraction[0]+\"-\"+date_extraction[-1]+\")_Candlestick_Pattern.csv\"\n",
        "print(output_filename_candlestick)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08WysvpF50ei"
      },
      "source": [
        "# Part 1: Combining Multiple CSV Together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS6s-b3mJi5f"
      },
      "source": [
        "## Extract CSV According to our Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VriYUxBk5s6R"
      },
      "outputs": [],
      "source": [
        "directory = internal_foldername\n",
        "\n",
        "csv_files = []\n",
        "# List the CSV files in the directory\n",
        "for date in date_extraction:\n",
        "  csv = [f for f in os.listdir(directory) if f.endswith(date+'.csv')]\n",
        "  if (len(csv)>0): csv_files.append(csv) # only append if a file is found\n",
        "\n",
        "# convert list of lists in 1-D array\n",
        "csv_files = np.reshape(csv_files, -1)\n",
        "print(csv_files)\n",
        "\n",
        "df_list = []\n",
        "\n",
        "# Loop through the CSV files and load them into DataFrames\n",
        "count = 0\n",
        "for file in csv_files:\n",
        "    # count += 1\n",
        "    # print(count)\n",
        "    # Load the CSV file into a DataFrame\n",
        "    df = pd.read_csv(os.path.join(directory, file), usecols = range(12))\n",
        "    # Append the DataFrame to the list\n",
        "    df_list.append(df)\n",
        "    # try:\n",
        "    #   df = pd.read_csv(os.path.join(directory, file),usecols=range(12))\n",
        "    #   df_list.append(df)\n",
        "    # except pd.errors.ParserError as e:\n",
        "    #   print(f\"Error reading file {file}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXgWVhU4JVCI"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iIg2yRDSaTc"
      },
      "outputs": [],
      "source": [
        "columns_to_numbers = [\"Balance\", \"Equity\", \"Delta\", \"% Difference\",\n",
        "                      \"Highest Balance\", \"Lowest Balance\",\n",
        "                      \"Highest Equity\", \"Lowest Equity\",\n",
        "                      \"Used Margin\", \"Free Margin\"]\n",
        "\n",
        "\n",
        "df_list_updated = []\n",
        "\n",
        "# go into each df csv and add the columns and calculations\n",
        "count =0\n",
        "for df in df_list:\n",
        "  count+=1\n",
        "  print(count)\n",
        "  for col in columns_to_numbers:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "\n",
        "  df[\"Starting Day Balance\"] = df[\"Balance\"][0]\n",
        "  df[\"Starting Day Equity\"] = df[\"Equity\"][0]\n",
        "\n",
        "  # Before calculations, if there is a big change in balance (withdrawn or balance changed by user) then change starting day balance and equity accordingly\n",
        "  prev_row = [0.0 for i in range(len(df)-1)]\n",
        "  current_row = [0.0 for i in range(len(df)-1)]\n",
        "  diff_row = [0.0 for i in range(len(df))] # current row - prev row\n",
        "  diff_percentage_row = [0.0 for i in range(len(df))]\n",
        "  big_change_row = [False for i in range(len(df))]\n",
        "\n",
        "  prev_row = df[\"Balance\"][:-1]\n",
        "  current_row = df[\"Balance\"][1:]\n",
        "\n",
        "  prev_row.reset_index(drop = True)\n",
        "  current_row.reset_index(drop = True)\n",
        "\n",
        "  prev_row = np.array(prev_row)\n",
        "  current_row = np.array(current_row)\n",
        "  diff_row = np.array(diff_row)\n",
        "  diff_row[1:] = np.abs(current_row - prev_row)\n",
        "  diff_percentage_row[1:] = diff_row[1:]/prev_row\n",
        "\n",
        "  diff_percentage_row = np.array(diff_percentage_row)\n",
        "  big_change_row = np.array(big_change_row)\n",
        "  big_change_row = diff_percentage_row > diff_percentage\n",
        "\n",
        "  indices_change = np.argwhere(big_change_row)\n",
        "  indices_change = np.array(indices_change).reshape(-1,)\n",
        "  indices_change = np.sort(indices_change)\n",
        "  for index in indices_change:\n",
        "    df[\"Starting Day Balance\"][index:] = df[\"Balance\"][index]\n",
        "    df[\"Starting Day Equity\"][index:] = df[\"Equity\"][index]\n",
        "\n",
        "  # Adding new columns to it\n",
        "  df[\"% Difference from Balance\"] = (df[\"Equity\"] - df[\"Starting Day Balance\"])/df[\"Starting Day Balance\"]\n",
        "  df[\"% Difference from Equity\"] = (df[\"Equity\"] - df[\"Starting Day Equity\"])/df[\"Starting Day Equity\"]\n",
        "\n",
        "  df_list_updated.append(df)\n",
        "\n",
        "\n",
        "df = pd.concat(df_list_updated, ignore_index=True)\n",
        "\n",
        "\n",
        "# Delete NA rows and columns headers if mixed within the data\n",
        "print(\"Number of data:\", len(df))\n",
        "indices_to_drop = df[df[\"Time\"] == \"Time\"].index\n",
        "df.drop(indices_to_drop, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "print()\n",
        "print(\"Number of updated rows:\", len(df))\n",
        "\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y.%m.%d\")\n",
        "# try:\n",
        "#     df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y.%m.%d\")\n",
        "# except ValueError as e:\n",
        "#     print(f\"Error converting date to datetime: {e}\")\n",
        "#     problematic_values = df.loc[pd.to_datetime(df[\"Date\"], errors='coerce').isna(), \"Date\"]\n",
        "#     print(f\"Problematic values: {problematic_values}\")\n",
        "\n",
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H:%M:%S\").dt.time\n",
        "\n",
        "# for col in columns_to_numbers:\n",
        "#     df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df[\"% Difference from Balance\"] = pd.to_numeric(df[\"% Difference from Balance\"], errors = \"coerce\")\n",
        "df[\"% Difference from Equity\"] = pd.to_numeric(df[\"% Difference from Equity\"], errors = \"coerce\")\n",
        "\n",
        "df = df.sort_values(by=[\"Date\", \"Time\"])\n",
        "df = df.reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELou-cLiJZCS"
      },
      "source": [
        "## Output Combined CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "l6s3H-M920Yg"
      },
      "outputs": [],
      "source": [
        "df.to_csv(output_filename, index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wUGwEj95lpk"
      },
      "source": [
        "# Part 2: CandleStick Chart Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsulgsTt6_CM"
      },
      "source": [
        "## Combined CSV file partioned in time interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bxTGiMSO6V06"
      },
      "outputs": [],
      "source": [
        "# end_day + 1 needs to be done to get data for end_day in candlestick chart\n",
        "time_interval = pd.date_range(start=start_date, end=datetime(end_year, end_month, end_day+1), freq=time_frequency)\n",
        "\n",
        "time_partition_arraylist = []\n",
        "\n",
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H:%M:%S\")\n",
        "# df.info()\n",
        "# df[\"Time\"][0]\n",
        "df[\"DateTime\"] = df[\"Date\"] + (df[\"Time\"] - datetime(1900, 1, 1, 0, 0, 0)) # normalize and combine date and time\n",
        "# df[\"DateTime\"]\n",
        "for i in range(len(time_interval)-1):\n",
        "  time_partition_arraylist.append(df[(df[\"DateTime\"]>=time_interval[i]) & (df[\"DateTime\"]<time_interval[i+1])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n74reu2I7V4L"
      },
      "source": [
        "## Making a new CSV table with candlestick chart style data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6ahn7zU7hHt"
      },
      "outputs": [],
      "source": [
        "df_time_partition = pd.DataFrame(index=range(len(time_partition_arraylist)))\n",
        "\n",
        "# Balance\n",
        "# df_time_partition[\"DateTime\"] = df[\"DateTime\"]\n",
        "df_time_partition[\"DateTime\"] = time_interval[:-1]\n",
        "df_time_partition[\"Balance Open\"] = 0.0\n",
        "df_time_partition[\"Balance Close\"] = 0.0\n",
        "df_time_partition[\"Balance High\"] = 0.0\n",
        "df_time_partition[\"Balance Low\"] = 0.0\n",
        "\n",
        "# Equity\n",
        "df_time_partition[\"Equity Open\"] = 0.0\n",
        "df_time_partition[\"Equity Close\"] = 0.0\n",
        "df_time_partition[\"Equity High\"] = 0.0\n",
        "df_time_partition[\"Equity Low\"] = 0.0\n",
        "\n",
        "# Used Margin\n",
        "df_time_partition[\"Used Margin Open\"] = 0.0\n",
        "df_time_partition[\"Used Margin Close\"] = 0.0\n",
        "df_time_partition[\"Used Margin High\"] = 0.0\n",
        "df_time_partition[\"Used Margin Low\"] = 0.0\n",
        "\n",
        "# Free Margin\n",
        "df_time_partition[\"Free Margin Open\"] = 0.0\n",
        "df_time_partition[\"Free Margin Close\"] = 0.0\n",
        "df_time_partition[\"Free Margin High\"] = 0.0\n",
        "df_time_partition[\"Free Margin Low\"] = 0.0\n",
        "\n",
        "# % Difference from Balance\n",
        "df_time_partition[\"% Difference from Balance Open\"] = 0.0\n",
        "df_time_partition[\"% Difference from Balance Close\"] = 0.0\n",
        "df_time_partition[\"% Difference from Balance High\"] = 0.0\n",
        "df_time_partition[\"% Difference from Balance Low\"] = 0.0\n",
        "\n",
        "# % Difference from Equity\n",
        "df_time_partition[\"% Difference from Equity Open\"] = 0.0\n",
        "df_time_partition[\"% Difference from Equity Close\"] = 0.0\n",
        "df_time_partition[\"% Difference from Equity High\"] = 0.0\n",
        "df_time_partition[\"% Difference from Equity Low\"] = 0.0\n",
        "\n",
        "\n",
        "for i in range(len(time_partition_arraylist)):\n",
        "  # df_time_partition[\"Time\"][i] = time_interval[i+1]\n",
        "  if (len(time_partition_arraylist[i])==0):\n",
        "    if (i==0):\n",
        "      # balance\n",
        "      df_time_partition[\"Balance Open\"][i] = df[\"Balance\"][i]\n",
        "      df_time_partition[\"Balance Close\"][i] = df[\"Balance\"][i]\n",
        "      df_time_partition[\"Balance High\"][i] = df[\"Balance\"][i]\n",
        "      df_time_partition[\"Balance Low\"][i] = df[\"Balance\"][i]\n",
        "\n",
        "      # equity\n",
        "      df_time_partition[\"Equity Open\"][i] = df[\"Equity\"][i]\n",
        "      df_time_partition[\"Equity Close\"][i] = df[\"Equity\"][i]\n",
        "      df_time_partition[\"Equity High\"][i] = df[\"Equity\"][i]\n",
        "      df_time_partition[\"Equity Low\"][i] = df[\"Equity\"][i]\n",
        "\n",
        "      # used margin\n",
        "      df_time_partition[\"Used Margin Open\"][i] = df[\"Used Margin\"][i]\n",
        "      df_time_partition[\"Used Margin Close\"][i] = df[\"Used Margin\"][i]\n",
        "      df_time_partition[\"Used Margin High\"][i] = df[\"Used Margin\"][i]\n",
        "      df_time_partition[\"Used Margin Low\"][i] = df[\"Used Margin\"][i]\n",
        "\n",
        "      # free margin\n",
        "      df_time_partition[\"Free Margin Open\"][i] = df[\"Free Margin\"][i]\n",
        "      df_time_partition[\"Free Margin Close\"][i] = df[\"Free Margin\"][i]\n",
        "      df_time_partition[\"Free Margin High\"][i] = df[\"Free Margin\"][i]\n",
        "      df_time_partition[\"Free Margin Low\"][i] = df[\"Free Margin\"][i]\n",
        "\n",
        "      # % Difference from Balance\n",
        "      df_time_partition[\"% Difference from Balance Open\"][i] = df[\"% Difference from Balance\"][i]\n",
        "      df_time_partition[\"% Difference from Balance Close\"][i] = df[\"% Difference from Balance\"][i]\n",
        "      df_time_partition[\"% Difference from Balance High\"][i] = df[\"% Difference from Balance\"][i]\n",
        "      df_time_partition[\"% Difference from Balance Low\"][i] = df[\"% Difference from Balance\"][i]\n",
        "\n",
        "      # % Difference from Equity\n",
        "      df_time_partition[\"% Difference from Equity Open\"][i] = df[\"% Difference from Equity\"][i]\n",
        "      df_time_partition[\"% Difference from Equity Close\"][i] = df[\"% Difference from Equity\"][i]\n",
        "      df_time_partition[\"% Difference from Equity High\"][i] = df[\"% Difference from Equity\"][i]\n",
        "      df_time_partition[\"% Difference from Equity Low\"][i] = df[\"% Difference from Equity\"][i]\n",
        "\n",
        "    else:\n",
        "      # balance\n",
        "      df_time_partition[\"Balance Open\"][i] = df_time_partition[\"Balance Close\"][i-1]\n",
        "      df_time_partition[\"Balance Close\"][i] = df_time_partition[\"Balance Close\"][i-1]\n",
        "      df_time_partition[\"Balance High\"][i] = df_time_partition[\"Balance Close\"][i-1]\n",
        "      df_time_partition[\"Balance Low\"][i] = df_time_partition[\"Balance Close\"][i-1]\n",
        "\n",
        "      # equity\n",
        "      df_time_partition[\"Equity Open\"][i] = df_time_partition[\"Equity Close\"][i-1]\n",
        "      df_time_partition[\"Equity Close\"][i] = df_time_partition[\"Equity Close\"][i-1]\n",
        "      df_time_partition[\"Equity High\"][i] = df_time_partition[\"Equity Close\"][i-1]\n",
        "      df_time_partition[\"Equity Low\"][i] = df_time_partition[\"Equity Close\"][i-1]\n",
        "\n",
        "      # used margin\n",
        "      df_time_partition[\"Used Margin Open\"][i] = df_time_partition[\"Used Margin Close\"][i-1]\n",
        "      df_time_partition[\"Used Margin Close\"][i] = df_time_partition[\"Used Margin Close\"][i-1]\n",
        "      df_time_partition[\"Used Margin High\"][i] = df_time_partition[\"Used Margin Close\"][i-1]\n",
        "      df_time_partition[\"Used Margin Low\"][i] = df_time_partition[\"Used Margin Close\"][i-1]\n",
        "\n",
        "      # free margin\n",
        "      df_time_partition[\"Free Margin Open\"][i] = df_time_partition[\"Free Margin Close\"][i-1]\n",
        "      df_time_partition[\"Free Margin Close\"][i] = df_time_partition[\"Free Margin Close\"][i-1]\n",
        "      df_time_partition[\"Free Margin High\"][i] = df_time_partition[\"Free Margin Close\"][i-1]\n",
        "      df_time_partition[\"Free Margin Low\"][i] = df_time_partition[\"Free Margin Close\"][i-1]\n",
        "\n",
        "      # % Difference from Balance\n",
        "      df_time_partition[\"% Difference from Balance Open\"][i] = df_time_partition[\"% Difference from Balance Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Balance Close\"][i] = df_time_partition[\"% Difference from Balance Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Balance High\"][i] = df_time_partition[\"% Difference from Balance Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Balance Low\"][i] = df_time_partition[\"% Difference from Balance Close\"][i-1]\n",
        "\n",
        "      # % Difference from Equity\n",
        "      df_time_partition[\"% Difference from Equity Open\"][i] = df_time_partition[\"% Difference from Equity Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Equity Close\"][i] = df_time_partition[\"% Difference from Equity Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Equity High\"][i] = df_time_partition[\"% Difference from Equity Close\"][i-1]\n",
        "      df_time_partition[\"% Difference from Equity Low\"][i] = df_time_partition[\"% Difference from Equity Close\"][i-1]\n",
        "\n",
        "\n",
        "\n",
        "  else:\n",
        "    # balance\n",
        "    df_time_partition[\"Balance Open\"][i] = time_partition_arraylist[i][\"Balance\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"Balance Close\"][i] = time_partition_arraylist[i][\"Balance\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"Balance High\"][i] = time_partition_arraylist[i][\"Balance\"].max()\n",
        "    df_time_partition[\"Balance Low\"][i] = time_partition_arraylist[i][\"Balance\"].min()\n",
        "\n",
        "    # equity\n",
        "    df_time_partition[\"Equity Open\"][i] = time_partition_arraylist[i][\"Equity\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"Equity Close\"][i] = time_partition_arraylist[i][\"Equity\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"Equity High\"][i] = time_partition_arraylist[i][\"Equity\"].max()\n",
        "    df_time_partition[\"Equity Low\"][i] = time_partition_arraylist[i][\"Equity\"].min()\n",
        "\n",
        "    # used margin\n",
        "    df_time_partition[\"Used Margin Open\"][i] = time_partition_arraylist[i][\"Used Margin\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"Used Margin Close\"][i] = time_partition_arraylist[i][\"Used Margin\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"Used Margin High\"][i] = time_partition_arraylist[i][\"Used Margin\"].max()\n",
        "    df_time_partition[\"Used Margin Low\"][i] = time_partition_arraylist[i][\"Used Margin\"].min()\n",
        "\n",
        "    # free margin\n",
        "    df_time_partition[\"Free Margin Open\"][i] = time_partition_arraylist[i][\"Free Margin\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"Free Margin Close\"][i] = time_partition_arraylist[i][\"Free Margin\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"Free Margin High\"][i] = time_partition_arraylist[i][\"Free Margin\"].max()\n",
        "    df_time_partition[\"Free Margin Low\"][i] = time_partition_arraylist[i][\"Free Margin\"].min()\n",
        "\n",
        "    # difference from balance\n",
        "    df_time_partition[\"% Difference from Balance Open\"][i] = time_partition_arraylist[i][\"% Difference from Balance\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"% Difference from Balance Close\"][i] = time_partition_arraylist[i][\"% Difference from Balance\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"% Difference from Balance High\"][i] = time_partition_arraylist[i][\"% Difference from Balance\"].max()\n",
        "    df_time_partition[\"% Difference from Balance Low\"][i] = time_partition_arraylist[i][\"% Difference from Balance\"].min()\n",
        "\n",
        "    # difference from equity\n",
        "    df_time_partition[\"% Difference from Equity Open\"][i] = time_partition_arraylist[i][\"% Difference from Equity\"][time_partition_arraylist[i].index[0]]\n",
        "    df_time_partition[\"% Difference from Equity Close\"][i] = time_partition_arraylist[i][\"% Difference from Equity\"][time_partition_arraylist[i].index[-1]]\n",
        "    df_time_partition[\"% Difference from Equity High\"][i] = time_partition_arraylist[i][\"% Difference from Equity\"].max()\n",
        "    df_time_partition[\"% Difference from Equity Low\"][i] = time_partition_arraylist[i][\"% Difference from Equity\"].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN221Qw57zJw"
      },
      "source": [
        "## CandleStick Chart Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7UE7kPrD72Qn"
      },
      "outputs": [],
      "source": [
        "df_balance = pd.DataFrame(index=range(len(time_partition_arraylist)))\n",
        "df_equity = pd.DataFrame(index=range(len(time_partition_arraylist)))\n",
        "df_dfb = pd.DataFrame(index=range(len(time_partition_arraylist)))\n",
        "df_dfe = pd.DataFrame(index=range(len(time_partition_arraylist)))\n",
        "\n",
        "# df_test[\"DateTime\"] = df_time_partition[\"Date\"] + (df_time_partition[\"Time\"] - datetime(1900, 1, 1, 0, 0, 0))\n",
        "df_balance[\"DateTime\"] = df_time_partition[\"DateTime\"]\n",
        "df_balance[\"Open\"] = df_time_partition[\"Balance Open\"]\n",
        "df_balance[\"Close\"] = df_time_partition[\"Balance Close\"]\n",
        "df_balance[\"High\"] = df_time_partition[\"Balance High\"]\n",
        "df_balance[\"Low\"] = df_time_partition[\"Balance Low\"]\n",
        "\n",
        "df_equity[\"DateTime\"] = df_time_partition[\"DateTime\"]\n",
        "df_equity[\"Open\"] = df_time_partition[\"Equity Open\"]\n",
        "df_equity[\"Close\"] = df_time_partition[\"Equity Close\"]\n",
        "df_equity[\"High\"] = df_time_partition[\"Equity High\"]\n",
        "df_equity[\"Low\"] = df_time_partition[\"Equity Low\"]\n",
        "\n",
        "df_dfb[\"DateTime\"] = df_time_partition[\"DateTime\"]\n",
        "df_dfb[\"Open\"] = df_time_partition[\"% Difference from Balance Open\"]*100\n",
        "df_dfb[\"Close\"] = df_time_partition[\"% Difference from Balance Close\"]*100\n",
        "df_dfb[\"High\"] = df_time_partition[\"% Difference from Balance High\"]*100\n",
        "df_dfb[\"Low\"] = df_time_partition[\"% Difference from Balance Low\"]*100\n",
        "\n",
        "df_dfe[\"DateTime\"] = df_time_partition[\"DateTime\"]\n",
        "df_dfe[\"Open\"] = df_time_partition[\"% Difference from Equity Open\"]*100\n",
        "df_dfe[\"Close\"] = df_time_partition[\"% Difference from Equity Close\"]*100\n",
        "df_dfe[\"High\"] = df_time_partition[\"% Difference from Equity High\"]*100\n",
        "df_dfe[\"Low\"] = df_time_partition[\"% Difference from Equity Low\"]*100\n",
        "\n",
        "df_balance.set_index(\"DateTime\", inplace=True)\n",
        "df_equity.set_index(\"DateTime\", inplace=True)\n",
        "df_dfb.set_index(\"DateTime\", inplace=True)\n",
        "df_dfe.set_index(\"DateTime\", inplace=True)\n",
        "\n",
        "mpf.plot(df_balance, type='candle', style='yahoo', tight_layout=True, title = output_title+ ' (Balance)', ylabel=\"Price/USD\", figratio=(20,10), savefig=output_title+ ' (Balance)')\n",
        "mpf.plot(df_equity, type='candle', style='yahoo', tight_layout=True, title = output_title+ ' (Equity)', ylabel=\"Price/USD\", figratio=(20,10), savefig=output_title+ ' (Equity)')\n",
        "mpf.plot(df_dfb, type='candle', style='yahoo', tight_layout=True, title = output_title+ ' (% Difference from Balance)', ylabel=\"% Change\", figratio=(20,10), savefig=output_title+ ' (% Difference from Balance)')\n",
        "mpf.plot(df_dfe, type='candle', style='yahoo', tight_layout=True, title = output_title+ ' (% Difference from Equity)', ylabel=\"% Change\", figratio=(20,10), savefig=output_title+ ' (% Difference from Equity)')\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "df_time_partition.to_csv(output_filename_candlestick, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6S8NvPCakKh"
      },
      "source": [
        "# Part 3: Combine Images in 2 x 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3g6hBI7xatlk"
      },
      "outputs": [],
      "source": [
        "# Set the directory containing the PNG files\n",
        "input_directory = \"\"\n",
        "\n",
        "# Set the output file name and path\n",
        "# output_file = \"/content/combined.png\"\n",
        "output_file = output_title+\".png\"\n",
        "\n",
        "# List all PNG files in the input directory\n",
        "# only png files have \").png\" to\n",
        "png_files = [f for f in os.listdir(input_directory) if (f.startswith(output_title) and f.endswith(\").png\"))]\n",
        "\n",
        "# Create a list to store images\n",
        "images = []\n",
        "\n",
        "# Loop through each PNG file and append it to the images list\n",
        "for png_file in png_files:\n",
        "    file_path = os.path.join(input_directory, png_file)\n",
        "    img = Image.open(file_path)\n",
        "    images.append(img)\n",
        "\n",
        "x_offset = images[0].width\n",
        "y_offset = images[0].height\n",
        "\n",
        "# Combine the images in (2 x 2) array\n",
        "combined_image = Image.new(\"RGB\", (x_offset*2, y_offset*2))\n",
        "\n",
        "# this numbering is done in a certain way so that\n",
        "# balance and equity and dfb, dfe appears a certain way\n",
        "combined_image.paste(images[0], (0,0))\n",
        "combined_image.paste(images[3], (x_offset, 0))\n",
        "combined_image.paste(images[2], (0, y_offset))\n",
        "combined_image.paste(images[1], (x_offset, y_offset))\n",
        "\n",
        "# Save the combined image\n",
        "combined_image.save(output_file)\n",
        "\n",
        "# Delete individual files\n",
        "for png_file in png_files:\n",
        "    file_path = os.path.join(input_directory, png_file)\n",
        "    os.remove(file_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RS6s-b3mJi5f",
        "ELou-cLiJZCS",
        "1wUGwEj95lpk",
        "MsulgsTt6_CM",
        "n74reu2I7V4L",
        "JN221Qw57zJw",
        "U6S8NvPCakKh"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
